params:
  batch_size: 4
  learning_rate: 5e-5
  embedding_size: 32
  layer: 6
  MHA: 4
  mlp_dim: 512
  dropout: 0.1
